"""
Seed Fund Experiment (Phase 2)

Protocol:
1. Train on Task A (COUNT_UP, proxy for TinyStories)
2. Freeze Core â†’ Expand with Directed Synergy
3. Train on Task B (COUNT_DOWN, proxy for BBC News)

Required Metrics:
- Stability: Task A PPL stays flat (or rises minimally) during Task B training
- Plasticity: Task B PPL drops to baseline levels

Success Criteria:
- Probe_Loss (Task A) < 2.0 throughout Task B training
- Loss (Task B) drops to < 1.0 within 500 steps
"""

import os
import torch
import math
from datetime import datetime
from dge_model import DGESimpleTransformer
from dge_training import train_task, TaskType, generate_batch, evaluate_task
from dge_utils import DGEAdamW, ExperienceReplayPenalty
from dge_logger import DGELogger


def compute_perplexity(model, task_type, vocab_size, batch_size=32, seq_len=32, samples=10):
    """
    Compute perplexity on a given task.
    
    Args:
        model: The model to evaluate
        task_type: TaskType enum (COUNT_UP or COUNT_DOWN)
        vocab_size: Vocabulary size
        batch_size: Batch size for evaluation
        seq_len: Sequence length
        samples: Number of batches to average over
        
    Returns:
        Average perplexity across samples
    """
    model.eval()
    total_loss = 0.0
    
    with torch.no_grad():
        for _ in range(samples):
            x, y = generate_batch(task_type, vocab_size, batch_size, seq_len)
            _, loss = model(x, y)
            total_loss += loss.item()
            
    avg_loss = total_loss / samples
    ppl = math.exp(avg_loss) if avg_loss < 100 else float('inf')
    
    model.train()
    return ppl


def run_seed_fund_experiment():
    """
    Main experiment: Prove Directed Synergy enables learning Task B 
    while preserving Task A.
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_name = f"dge_seed_fund_{timestamp}"
    models_dir = os.path.join(os.getcwd(), 'models')
    os.makedirs(models_dir, exist_ok=True)
    exp_dir = os.path.join(models_dir, model_name)
    
    # Initialize Logger
    logger = DGELogger(exp_dir)
    
    # Model Configuration
    vocab_size = 500
    d_model = 64
    n_layer = 2
    n_head = 4
    
    print("=" * 60)
    print("ðŸ§ª SEED FUND EXPERIMENT: Directed Synergy Validation")
    print("=" * 60)
    print(f"Model: {model_name}")
    print(f"Config: vocab={vocab_size}, d_model={d_model}, layers={n_layer}, heads={n_head}")
    print()
    
    # ===== PHASE 1: TRAIN SKILL A (SEED FUND) =====
    print("=" * 60)
    print("ðŸ“š PHASE 1: Training Task A (Seed Fund)")
    print("=" * 60)
    
    model = DGESimpleTransformer(
        vocab_size=vocab_size, 
        d_model=d_model, 
        n_layer=n_layer, 
        n_head=n_head
    )
    
    optimizer = DGEAdamW(model.parameters(), lr=1e-3, weight_decay=0.0)
    global_step = 0
    
    # Train Task A
    global_step = train_task(
        model, TaskType.COUNT_UP, 
        vocab_size=vocab_size, 
        steps=500,
        logger=logger, 
        start_step=global_step, 
        optimizer=optimizer
    )
    
    # Evaluate Task A baseline
    ppl_a_baseline = compute_perplexity(model, TaskType.COUNT_UP, vocab_size)
    acc_a_baseline = evaluate_task(model, TaskType.COUNT_UP, vocab_size)
    
    print(f"\nâœ… Task A Baseline:")
    print(f"   PPL: {ppl_a_baseline:.2f}")
    print(f"   Accuracy: {acc_a_baseline:.1f}%")
    
    logger.log_event("PHASE1_COMPLETE", {
        "task_a_ppl": ppl_a_baseline,
        "task_a_acc": acc_a_baseline
    }, step=global_step)
    
    # ===== PHASE 2: FREEZE CORE & EXPAND =====
    print("\n" + "=" * 60)
    print("ðŸ”’ PHASE 2: Freezing Core & Expanding with Synergy")
    print("=" * 60)
    
    current_d_model = model.d_model
    added_width = 32
    
    # Expand with DIRECTED SYNERGY settings
    # NOTE: use_orthogonal_init=False is CRITICAL!
    # Orthogonal init scales weights by 0.1, causing signal attenuation (Dead Sidecar).
    #
    # CRITICAL V 0.3.2: router_init_bias=-4.0 (gates DEFAULT CLOSED)
    # This ensures new parameters don't interfere with old task patterns.
    # Gradient rescue allows gates to LEARN to open for new task patterns.
    model.expand_model(
        new_input_dim=current_d_model + added_width,
        new_output_dim=vocab_size,
        router_type='bigram',             # V26: Contextual Router (Disambiguates A vs B)
        use_orthogonal_init=False,
        use_gradient_rescue=True,       # CRITICAL: Allows learning despite closed gates
        isolate_cross_terms=False,
        router_init_bias=0.0,            # V25: Start OPEN for Plasticity
        gating_threshold=0.0             # Soft gating matches 0.0 bias
    )
    
    # Verify identity preservation
    ppl_a_post_expand = compute_perplexity(model, TaskType.COUNT_UP, vocab_size)
    acc_a_post_expand = evaluate_task(model, TaskType.COUNT_UP, vocab_size)
    
    print(f"\nâœ… Post-Expansion Task A:")
    print(f"   PPL: {ppl_a_post_expand:.2f} (Î” = {ppl_a_post_expand - ppl_a_baseline:+.2f})")
    print(f"   Accuracy: {acc_a_post_expand:.1f}% (Î” = {acc_a_post_expand - acc_a_baseline:+.1f}%)")
    
    identity_preserved = abs(ppl_a_post_expand - ppl_a_baseline) < 0.5
    print(f"   Identity Preserved: {'âœ… YES' if identity_preserved else 'âŒ NO'}")
    
    logger.log_event("PHASE2_EXPAND", {
        "task_a_ppl_post": ppl_a_post_expand,
        "task_a_acc_post": acc_a_post_expand,
        "identity_preserved": identity_preserved,
        "added_width": added_width
    }, step=global_step)
    
    # Re-initialize optimizer for new parameters
    router_params = [p for n, p in model.named_parameters() if 'router' in n or 'gate' in n]
    default_params = [p for n, p in model.named_parameters() if 'router' not in n and 'gate' not in n]
    
    optimizer = DGEAdamW([
        {'params': default_params, 'lr': 1e-3},
        {'params': router_params, 'lr': 1e-3}
    ], weight_decay=0.0)
    
    # ===== PHASE 3: TRAIN TASK B (DIRECTED SYNERGY) =====
    print("\n" + "=" * 60)
    print("ðŸŽ¯ PHASE 3: Training Task B with Directed Synergy")
    print("=" * 60)
    
    # Track metrics during training
    stability_log = []
    plasticity_log = []
    
    # Custom training loop with EXPERIENCE REPLAY
    # CRITICAL: Without replay, router never learns to close for Task A patterns
    steps = 500
    batch_size = 32
    seq_len = 32
    replay_ratio = 0.5  # 50% Task A replay, 50% Task B new learning
    
    model.train()
    for i in range(steps):
        optimizer.zero_grad()
        
        # ASYMMETRIC REPLAY (V23)
        if i % 2 == 0:
            # Task B (Plasticity): Train EVERYTHING (Weights + Routers)
            # Router learns to OPEN (to use new capacity)
            x, y = generate_batch(TaskType.COUNT_DOWN, vocab_size, batch_size, seq_len)
            logits, loss = model(x, y, sparsity_lambda=0.05)
            loss.backward()
            
        else:
            # Task A (Stability): Train ROUTERS ONLY (Freeze Weights)
            # Weights are specialized for B, so they look like noise to A.
            # Router learns to CLOSE (to reject noise)
            x, y = generate_batch(TaskType.COUNT_UP, vocab_size, batch_size, seq_len)
            logits, loss = model(x, y, sparsity_lambda=0.05)
            loss.backward()
            
            # CRITICAL: Grad Masking for Router-Only Training
            for name, param in model.named_parameters():
                if "router" not in name:
                    param.grad = None # Zero grad for weights/bias
        
        optimizer.step()
        
        # Log every 50 steps
        if i % 50 == 0 or i == steps - 1:
            ppl_b = compute_perplexity(model, TaskType.COUNT_DOWN, vocab_size, samples=3)
            ppl_a_probe = compute_perplexity(model, TaskType.COUNT_UP, vocab_size, samples=3)
            
            stability_log.append((i, ppl_a_probe))
            plasticity_log.append((i, ppl_b))
            
            print(f"Step {i:4d} | Task B PPL: {ppl_b:.2f} | Task A Probe PPL: {ppl_a_probe:.2f}")
            
            logger.log_training_step(global_step + i, "PHASE3", loss.item(), ppl_b, 0.0, {
                "probe_ppl": ppl_a_probe,
                "step_in_phase": i
            })
    
    global_step += steps
    
    # ===== FINAL EVALUATION =====
    print("\n" + "=" * 60)
    print("ðŸ“Š FINAL EVALUATION")
    print("=" * 60)
    
    ppl_a_final = compute_perplexity(model, TaskType.COUNT_UP, vocab_size)
    ppl_b_final = compute_perplexity(model, TaskType.COUNT_DOWN, vocab_size)
    acc_a_final = evaluate_task(model, TaskType.COUNT_UP, vocab_size)
    acc_b_final = evaluate_task(model, TaskType.COUNT_DOWN, vocab_size)
    
    print(f"\nðŸ“ˆ STABILITY (Task A Retention):")
    print(f"   Baseline PPL: {ppl_a_baseline:.2f}")
    print(f"   Final PPL:    {ppl_a_final:.2f}")
    print(f"   Î” PPL:        {ppl_a_final - ppl_a_baseline:+.2f}")
    print(f"   Accuracy:     {acc_a_final:.1f}%")
    
    stability_success = ppl_a_final < 2.0
    print(f"   SUCCESS: {'âœ… YES' if stability_success else 'âŒ NO'} (PPL < 2.0)")
    
    print(f"\nðŸ“‰ PLASTICITY (Task B Acquisition):")
    print(f"   Final PPL:    {ppl_b_final:.2f}")
    print(f"   Accuracy:     {acc_b_final:.1f}%")
    
    plasticity_success = ppl_b_final < 3.0  # More lenient than Task A baseline
    print(f"   SUCCESS: {'âœ… YES' if plasticity_success else 'âŒ NO'} (PPL < 3.0)")
    
    # Overall verdict
    print("\n" + "=" * 60)
    if stability_success and plasticity_success:
        print("ðŸ† DIRECTED SYNERGY: SUCCESS!")
        print("   âœ… Stability preserved (Task A)")
        print("   âœ… Plasticity achieved (Task B)")
    elif stability_success:
        print("âš ï¸ PARTIAL SUCCESS: Stability OK, Plasticity Failed")
        print("   Possible cause: Gates still too closed or signal attenuation")
    elif plasticity_success:
        print("âš ï¸ PARTIAL SUCCESS: Plasticity OK, Stability Failed")
        print("   Possible cause: Firewall leak or interference from Q_TL")
    else:
        print("âŒ FAILURE: Both metrics failed")
    print("=" * 60)
    
    logger.log_event("EXPERIMENT_COMPLETE", {
        "stability_success": stability_success,
        "plasticity_success": plasticity_success,
        "task_a_ppl_final": ppl_a_final,
        "task_b_ppl_final": ppl_b_final,
        "task_a_acc_final": acc_a_final,
        "task_b_acc_final": acc_b_final,
        "forgetting": ppl_a_final - ppl_a_baseline
    }, step=global_step)
    
    print(f"\nðŸ“ Logs saved to: {exp_dir}")
    
    return {
        "stability_success": stability_success,
        "plasticity_success": plasticity_success,
        "forgetting": ppl_a_final - ppl_a_baseline,
        "task_a_ppl": ppl_a_final,
        "task_b_ppl": ppl_b_final
    }


if __name__ == "__main__":
    run_seed_fund_experiment()
